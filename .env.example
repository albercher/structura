# OpenAI API Key (required for OpenAI, optional for Ollama)
OPENAI_API_KEY=your_openai_api_key_here

# OpenAI Base URL (optional)
# Set to "http://localhost:11434/v1" to use Ollama locally
# Leave empty to use OpenAI's default API endpoint
OPENAI_BASE_URL=

# Firecrawl API Key (optional, if using Firecrawl cloud service)
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# LLM Configuration (optional)
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.3

# Debug Mode (optional)
# Set to "true" to include full tracebacks in error responses (default: false)  
# WARNING: Only enable in development, not in production
DEBUG=false
